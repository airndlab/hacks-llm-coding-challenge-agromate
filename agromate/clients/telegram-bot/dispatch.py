import base64
import io
import logging
import os
from typing import Optional

import aiohttp
import httpx
import yaml
from aiogram import Bot
from aiogram import Dispatcher
from aiogram.filters import CommandStart, Command
from aiogram.types import Message, ReactionTypeEmoji
from openai import OpenAI

from app_client import create_message, create_report
from config import settings
from models import ChatMessageCreateRequest

logger = logging.getLogger(__name__)

dp = Dispatcher()


# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²
def load_yaml_config(filename):
    config_path = os.path.join(settings.bot_configs_path, filename)
    try:
        with open(config_path, 'r', encoding='utf-8') as file:
            return yaml.safe_load(file)
    except Exception as e:
        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ {filename}: {e}")
        return {}


# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð²
prompts_config = load_yaml_config('prompts.yaml')
OCR_SYSTEM_PROMPT = prompts_config.get('ocr_system_prompt', '')

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ LLM
llm_config = load_yaml_config('models.yaml')
llm_model = llm_config.get('ocr_model_name', 'gpt-4o')
audio_model = llm_config.get('audio_model_name', 'whisper-1')


def load_messages(path=settings.bot_messages_path) -> dict:
    with open(path, encoding="utf-8") as f:
        return yaml.safe_load(f)


msgs = load_messages()


# ÐšÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² base64
def encode_image(image_bytes: bytes) -> str:
    return base64.b64encode(image_bytes).decode("utf-8")


# Ð’Ñ‹Ð·Ð¾Ð² OpenAI Vision API
async def transcribe_image(base64_image: str) -> str:
    try:
        client = OpenAI(api_key=settings.ocr_api_key)
        response = client.chat.completions.create(
            model=llm_model,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": OCR_SYSTEM_PROMPT},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            },
                        },
                    ],
                }
            ],
            max_tokens=4096
        )
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"Error in transcribe_image: {e}", exc_info=True)
        return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: {str(e)}"


# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸Ð· ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
async def download_photo(message: Message) -> Optional[bytes]:
    if not message.photo:
        return None

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ„Ð¾Ñ‚Ð¾ Ð½Ð°Ð¸Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° (Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚ Ð² ÑÐ¿Ð¸ÑÐºÐµ)
    photo = message.photo[-1]

    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ URL Ñ„Ð°Ð¹Ð»Ð°
        file = await message.bot.get_file(photo.file_id)

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ URL Ð´Ð»Ñ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ
        file_path = file.file_path
        bot_token = settings.bot_token
        file_url = f"https://api.telegram.org/file/bot{bot_token}/{file_path}"

        # Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð» Ñ‡ÐµÑ€ÐµÐ· aiohttp
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(file_url) as response:
                    if response.status == 200:
                        return await response.read()
                    else:
                        logger.error(f"Error downloading file: HTTP {response.status}")
                        return None
        except Exception as e:
            logger.error(f"Error with aiohttp: {e}")

            # Ð—Ð°Ð¿Ð°ÑÐ½Ð¾Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ httpx
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(file_url)
                    if response.status_code == 200:
                        return response.content
                    else:
                        logger.error(f"Error downloading file with httpx: HTTP {response.status_code}")
                        return None
            except Exception as e2:
                logger.error(f"Error with httpx: {e2}")

                # ÐšÐ°Ðº Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½ÑƒÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ aiogram
                try:
                    return await message.bot.download_file(file.file_id)
                except Exception as e3:
                    logger.error(f"Error with aiogram download: {e3}")
                    return None
    except Exception as e:
        logger.error(f"Error getting file information: {e}")
        return None


# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¸Ð»Ð¸ Ð°ÑƒÐ´Ð¸Ð¾ Ð¸Ð· ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ
async def download_voice(message: Message) -> Optional[bytes]:
    content = message.voice or message.audio
    if not content:
        return None

    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ URL Ñ„Ð°Ð¹Ð»Ð°
        file = await message.bot.get_file(content.file_id)

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ URL Ð´Ð»Ñ ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ñ
        file_path = file.file_path
        bot_token = settings.bot_token
        file_url = f"https://api.telegram.org/file/bot{bot_token}/{file_path}"

        # Ð¡ÐºÐ°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð» Ñ‡ÐµÑ€ÐµÐ· aiohttp
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(file_url) as response:
                    if response.status == 200:
                        return await response.read()
                    else:
                        logger.error(f"Error downloading voice file: HTTP {response.status}")
                        return None
        except Exception as e:
            logger.error(f"Error with aiohttp for voice: {e}")

            # Ð—Ð°Ð¿Ð°ÑÐ½Ð¾Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ httpx
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(file_url)
                    if response.status_code == 200:
                        return response.content
                    else:
                        logger.error(f"Error downloading voice file with httpx: HTTP {response.status_code}")
                        return None
            except Exception as e2:
                logger.error(f"Error with httpx for voice: {e2}")

                # ÐšÐ°Ðº Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ - Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½ÑƒÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ aiogram
                try:
                    return await message.bot.download_file(file.file_id)
                except Exception as e3:
                    logger.error(f"Error with aiogram download for voice: {e3}")
                    return None
    except Exception as e:
        logger.error(f"Error getting voice file information: {e}")
        return None


# Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð°Ñ†Ð¸Ñ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· OpenAI API
async def transcribe_audio(audio_bytes: bytes) -> str:
    try:
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
        temp_file = io.BytesIO(audio_bytes)
        temp_file.name = "audio.ogg"  # Ð˜Ð¼Ñ Ñ„Ð°Ð¹Ð»Ð° Ñ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸ÐµÐ¼

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚ OpenAI Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¼ API ÐºÐ»ÑŽÑ‡Ð¾Ð¼
        client = OpenAI(api_key=settings.audio_api_key)

        # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ API Ð´Ð»Ñ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð°Ñ†Ð¸Ð¸
        response = client.audio.transcriptions.create(
            model=audio_model,
            file=temp_file
        )

        return response.text
    except Exception as e:
        logger.error(f"Error in transcribe_audio: {e}", exc_info=True)
        return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð°Ñ†Ð¸Ð¸ Ð°ÑƒÐ´Ð¸Ð¾: {str(e)}"


# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ‚ÐµÐºÑÑ‚Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ (Ð¸ Ð´Ð»Ñ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ñ… ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹, Ð¸ Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Ñ„Ð¾Ñ‚Ð¾)
async def process_message_text(message: Message, text: str) -> None:
    if (message.forward_from and message.forward_from.username and message.forward_from.id):
        username = message.forward_from.username
        user_id = message.forward_from.id
    else:
        username = message.from_user.username
        user_id = message.from_user.id
    logger.info(f"Processing message from '{username}':\n{text}")
    created_message = await create_message(ChatMessageCreateRequest(
        username=str(username),
        user_id=str(user_id),
        chat_id=str(message.chat.id),
        message_id=str(message.message_id),
        message_text=text,
        created_at=message.date,
    ))
    logger.info(f"Created message from '{username}' with id: {created_message.id}")
    await message.react([ReactionTypeEmoji(emoji="ðŸ¤”")])


@dp.message(CommandStart())
async def command_start_handler(message: Message) -> None:
    await message.reply(msgs["start"].format())


@dp.message(Command('report'))
async def command_report_handler(message: Message):
    await message.react([ReactionTypeEmoji(emoji="ðŸ¤”")])
    report = await create_report()
    await message.reply((
        msgs["report"]
        .format(
            report_at=report.created_at.strftime('%d.%m.%Y %H:%M'),
            summary=report.summary,
            url=report.url,
        )
    ))
    await message.react([])


@dp.message(Command('schedule'))
async def command_schedule_handler(message: Message):
    parts = message.text.strip().split(maxsplit=1)
    if len(parts) == 2:
        time_arg = parts[1]
        await message.reply(msgs["schedule"]["success"].format(
            time=time_arg,
        ))
    else:
        await message.reply(msgs["schedule"]["error"].format())


@dp.message(Command('dashboard'))
async def command_dashboard_handler(message: Message):
    await message.reply(msgs["dashboard"].format(
        url=settings.dashboard_url
    ))


@dp.message(lambda message: message.photo)
async def photo_handler(message: Message) -> None:
    try:
        username = message.from_user.username
        logger.info(f"Received photo from '{username}'")

        # Ð ÐµÐ°Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð½Ð° ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¸ ÑÐ¾Ð¾Ð±Ñ‰Ð°ÐµÐ¼ Ð¾ Ð½Ð°Ñ‡Ð°Ð»Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        await message.react([ReactionTypeEmoji(emoji="ðŸ‘")])
        processing_msg = await message.reply("ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ð» Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸ÑŽ! ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ...")

        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ñ„Ð¾Ñ‚Ð¾
        photo_bytes = await download_photo(message)
        if not photo_bytes:
            await processing_msg.edit_text("ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.")
            return

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑŒ Ðº Ñ„Ð¾Ñ‚Ð¾, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
        caption = message.caption or ""
        if caption:
            logger.info(f"Photo caption: {caption}")
            await process_message_text(message, caption)
            await processing_msg.edit_text(f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» Ð¿Ð¾Ð´Ð¿Ð¸ÑÑŒ Ðº Ñ„Ð¾Ñ‚Ð¾: {caption}")
            return

        # ÐšÐ¾Ð´Ð¸Ñ€ÑƒÐµÐ¼ Ñ„Ð¾Ñ‚Ð¾ Ð² base64
        base64_image = encode_image(photo_bytes)

        # Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        recognized_text = await transcribe_image(base64_image)
        logger.info(f"Recognized text from photo: {recognized_text}")

        # Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¾Ð± Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ, Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚
        await processing_msg.edit_text(f"Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð» ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ñ‚ÐµÐºÑÑ‚:\n\n{recognized_text}\n\nÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ...")

        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ ÐºÐ°Ðº Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
        await process_message_text(message, recognized_text)

    except Exception as e:
        logger.error(f"Error in photo_handler: {e}", exc_info=True)
        await message.reply(f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸: {str(e)}")
        await message.react([ReactionTypeEmoji(emoji="ðŸ˜¢")])


@dp.message(lambda message: message.voice or message.audio)
async def voice_handler(message: Message) -> None:
    try:
        username = message.from_user.username
        is_voice = bool(message.voice)
        content_type = "Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ" if is_voice else "Ð°ÑƒÐ´Ð¸Ð¾Ñ„Ð°Ð¹Ð»"

        logger.info(f"Received {content_type} from '{username}'")

        # Ð’Ñ‹Ð²Ð¾Ð´ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸
        content = message.voice if is_voice else message.audio
        file_id = content.file_id
        duration = content.duration

        # Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ð¾Ðµ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¸
        extra_info = {}
        if is_voice and hasattr(content, 'mime_type'):
            extra_info['mime_type'] = content.mime_type
        if hasattr(content, 'file_size'):
            extra_info['file_size'] = content.file_size

        logger.info(f"Voice/Audio message details: file_id={file_id}, duration={duration}s, extra_info={extra_info}")

        # ÐžÑ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ Ð¾ Ð½Ð°Ñ‡Ð°Ð»Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        processing_msg = await message.reply(f"ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ð» {content_type}! Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: {duration} ÑÐµÐº. ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ...")

        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾
        audio_bytes = await download_voice(message)
        if not audio_bytes:
            await processing_msg.edit_text(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ {content_type}. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¿Ð¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ñ‘ Ñ€Ð°Ð·.")
            return

        # Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð¸Ñ€ÑƒÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾
        transcribed_text = await transcribe_audio(audio_bytes)
        logger.info(f"Transcribed text from voice: {transcribed_text}")

        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð¼ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð±Ð°Ñ†Ð¸Ð¸
        await processing_msg.edit_text(f"Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð» ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ñ‚ÐµÐºÑÑ‚:\n\n{transcribed_text}\n\nÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ...")

        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ ÐºÐ°Ðº Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ
        await process_message_text(message, transcribed_text)

        # Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑŒ Ðº Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¼Ñƒ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸ÑŽ
        caption = message.caption or ""
        if caption:
            logger.info(f"Voice/Audio caption: {caption}")
            await process_message_text(message, caption)

    except Exception as e:
        logger.error(f"Error in voice_handler: {e}", exc_info=True)
        await message.reply(f"ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ: {str(e)}")


@dp.message()
async def question_handler(message: Message) -> None:
    try:
        message_text = message.text
        await process_message_text(message, message_text)
    except Exception as e:
        logger.error(f"Error in question_handler: {e}", exc_info=True)
        await message.react([ReactionTypeEmoji(emoji="ðŸ˜¢")])


async def start_pooling(bot: Bot) -> None:
    await dp.start_polling(bot)

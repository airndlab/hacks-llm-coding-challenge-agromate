# Критерии оценки финального решения

## Критерий оценки: качество кода и архитектура

**Что оценивается?** Решение написано читаемо, логично, структурировано. Используются понятные имена переменных, читаемые классы и методы. Папки организованы понятно. Архитектура проекта допускает развитие.

- **0 баллов** - Код неструктурирован, запутан, названия бессмысленные, понять логику сложно.
- **1 балл** - Есть базовая структура, но код требует доработки: дублирование, странные названия, слабая организация.
- **2 балла** - Код чистый, читаемый, проект структурирован. Команда использовала хорошие практики и может обосновать выбор инструментов и архитектуры.

## Критерий оценки: эффективность и соответствие задаче

**Что оценивается?** MVP решает именно ту задачу, что была в кейсе. Учитываются технические и бизнес-требования.

- **0 баллов** - Решение не соответствует задаче. Команда сделала что-то свое, игнорируя условия и цель кейса.
- **1 балл** - Задача частично решена. Есть попытка реализовать нужное, но не все требования учтены, или результат сомнительный.
- **2 балла** - Задача полностью решена. Команда показала, что поняла бизнес-проблему и представила работающее, осмысленное решение, релевантное запросу.

## Критерий оценки: UX и интерфейс

**Что оценивается?** Пользовательский опыт: удобно ли пользоваться? Понятен ли интерфейс? Есть ли фидбек: ошибки, прогресс, подсказки? Не важен «дизайн ради дизайна», важна понятность.

- **0 баллов** - Непонятно, как пользоваться. Интерфейс или отсутствует, или делает работу неудобной.
- **1 балл** - Есть базовый интерфейс или пользовательский путь, но взаимодействие с продуктом не до конца продумано.
- **2 балла** - Интерфейс интуитивный, понятный. Есть обратная связь (ошибки, прогресс, статусы). Пользователю удобно работать с продуктом.

## Критерий оценки: применение LLM / кодинг-ассистентов

**Что оценивается?** Подтверждение того, что код действительно сгенерирован с помощью AI-инструментов. Важно понимание и осознанное использование. Команды должны в питче рассказать, какие фичи ассистентов они использовали.

- **0 баллов** - Нет доказательств использования LLM. Всё сделано руками или участники не могут объяснить, чем помог ассистент.
- **1 балл** - Использование LLM есть, но поверхностное. Ассистент применён для базовых задач, осознанного подхода нет.
- **2 балла** - Чётко видно, что LLM помог в ключевых частях проекта. Участники могут объяснить, что и как ассистент сгенерировал, и в чём была ценность.

## Критерий оценки: питч и презентация решения
**Вес критерия:** 0,75

**Что оценивается?** Оценивается только качество донесения смысла: понятен ли проект, логика, ход решения, демонстрация, как именно были применены LLM-модели в ходе работы над проектом.

- **0 баллов** - Презентация сбивчивая, нет логики. Непонятно, что команда сделала. Документации нет.
- **1 балл** - Решение представлено, но есть пробелы: слайды не структурированы, README неполный или запутанный.
- **2 балла** - Презентация ясная, логичная. Есть README с понятной инструкцией, репозиторий оформлен. Команда раскрыла идею проекта и то, как он работает.

## Чек-лист для самопроверки перед сдачей проекта

- [ ] Код организован логично и структурированно
- [ ] Нет дублирования кода, переменные и функции имеют понятные названия
- [ ] Проект решает поставленную бизнес-задачу полностью
- [ ] Учтены все технические требования из документации
- [ ] Интерфейс интуитивно понятен для пользователя
- [ ] Реализована обратная связь (сообщения об ошибках, индикаторы прогресса и т.д.)
- [ ] Подготовлены примеры использования LLM/кодинг-ассистентов в проекте
- [ ] Можем объяснить, как и где именно LLM помог в разработке
- [ ] Подготовлена четкая презентация проекта
- [ ] Написана понятная документация и инструкция по запуску 